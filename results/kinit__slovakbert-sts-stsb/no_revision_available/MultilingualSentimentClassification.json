{
    "dataset_revision": "2b9b4d10fc589af67794141fe8cbd3739de1eb33",
    "task_name": "MultilingualSentimentClassification",
    "mteb_version": "1.39.7",
    "scores": {
        "test": [
            {
                "accuracy": 0.866603,
                "f1": 0.784113,
                "f1_weighted": 0.884478,
                "ap": 0.978746,
                "ap_weighted": 0.978746,
                "scores_per_experiment": [
                    {
                        "accuracy": 0.863724,
                        "f1": 0.779497,
                        "f1_weighted": 0.882295,
                        "ap": 0.980915,
                        "ap_weighted": 0.980915
                    },
                    {
                        "accuracy": 0.886756,
                        "f1": 0.801888,
                        "f1_weighted": 0.899698,
                        "ap": 0.977489,
                        "ap_weighted": 0.977489
                    },
                    {
                        "accuracy": 0.90595,
                        "f1": 0.831742,
                        "f1_weighted": 0.91603,
                        "ap": 0.984915,
                        "ap_weighted": 0.984915
                    },
                    {
                        "accuracy": 0.861804,
                        "f1": 0.777245,
                        "f1_weighted": 0.880771,
                        "ap": 0.980647,
                        "ap_weighted": 0.980647
                    },
                    {
                        "accuracy": 0.798464,
                        "f1": 0.707992,
                        "f1_weighted": 0.830598,
                        "ap": 0.969863,
                        "ap_weighted": 0.969863
                    },
                    {
                        "accuracy": 0.866603,
                        "f1": 0.782055,
                        "f1_weighted": 0.88445,
                        "ap": 0.98036,
                        "ap_weighted": 0.98036
                    },
                    {
                        "accuracy": 0.922265,
                        "f1": 0.85236,
                        "f1_weighted": 0.928992,
                        "ap": 0.983402,
                        "ap_weighted": 0.983402
                    },
                    {
                        "accuracy": 0.880998,
                        "f1": 0.79626,
                        "f1_weighted": 0.895373,
                        "ap": 0.97857,
                        "ap_weighted": 0.97857
                    },
                    {
                        "accuracy": 0.896353,
                        "f1": 0.817065,
                        "f1_weighted": 0.907911,
                        "ap": 0.981668,
                        "ap_weighted": 0.981668
                    },
                    {
                        "accuracy": 0.783109,
                        "f1": 0.695023,
                        "f1_weighted": 0.818658,
                        "ap": 0.969626,
                        "ap_weighted": 0.969626
                    }
                ],
                "main_score": 0.866603,
                "hf_subset": "slk",
                "languages": [
                    "slk-Latn"
                ]
            }
        ]
    },
    "evaluation_time": 19.155185222625732,
    "kg_co2_emissions": null
}
