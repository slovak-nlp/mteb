{
    "dataset_revision": "382817850e097286b3fa9d874fb1b5128d0a430c",
    "task_name": "MultiEupSlovakGenderClassification",
    "mteb_version": "1.39.7",
    "scores": {
        "test": [
            {
                "accuracy": 0.572656,
                "f1": 0.497306,
                "f1_weighted": 0.62126,
                "ap": 0.878962,
                "ap_weighted": 0.878962,
                "scores_per_experiment": [
                    {
                        "accuracy": 0.46875,
                        "f1": 0.433333,
                        "f1_weighted": 0.532943,
                        "ap": 0.872832,
                        "ap_weighted": 0.872832
                    },
                    {
                        "accuracy": 0.3125,
                        "f1": 0.306404,
                        "f1_weighted": 0.352124,
                        "ap": 0.848497,
                        "ap_weighted": 0.848497
                    },
                    {
                        "accuracy": 0.710938,
                        "f1": 0.582474,
                        "f1_weighted": 0.745315,
                        "ap": 0.887557,
                        "ap_weighted": 0.887557
                    },
                    {
                        "accuracy": 0.453125,
                        "f1": 0.421338,
                        "f1_weighted": 0.516699,
                        "ap": 0.870291,
                        "ap_weighted": 0.870291
                    },
                    {
                        "accuracy": 0.5,
                        "f1": 0.433001,
                        "f1_weighted": 0.570044,
                        "ap": 0.854327,
                        "ap_weighted": 0.854327
                    },
                    {
                        "accuracy": 0.757812,
                        "f1": 0.608794,
                        "f1_weighted": 0.778562,
                        "ap": 0.88902,
                        "ap_weighted": 0.88902
                    },
                    {
                        "accuracy": 0.554688,
                        "f1": 0.485291,
                        "f1_weighted": 0.618178,
                        "ap": 0.8745,
                        "ap_weighted": 0.8745
                    },
                    {
                        "accuracy": 0.710938,
                        "f1": 0.610494,
                        "f1_weighted": 0.74957,
                        "ap": 0.90667,
                        "ap_weighted": 0.90667
                    },
                    {
                        "accuracy": 0.515625,
                        "f1": 0.474019,
                        "f1_weighted": 0.578034,
                        "ap": 0.886987,
                        "ap_weighted": 0.886987
                    },
                    {
                        "accuracy": 0.742188,
                        "f1": 0.61791,
                        "f1_weighted": 0.771129,
                        "ap": 0.898942,
                        "ap_weighted": 0.898942
                    }
                ],
                "main_score": 0.572656,
                "hf_subset": "default",
                "languages": [
                    "slk-Latn"
                ]
            }
        ]
    },
    "evaluation_time": 27.91255497932434,
    "kg_co2_emissions": null
}
