{
    "dataset_revision": "250a73199a3013bf9bf6b73b3fbdf83279b40375",
    "task_name": "DGurgurovSlovakSentiment",
    "mteb_version": "1.39.7",
    "scores": {
        "test": [
            {
                "accuracy": 0.749328,
                "f1": 0.643285,
                "f1_weighted": 0.787562,
                "ap": 0.941968,
                "ap_weighted": 0.941968,
                "scores_per_experiment": [
                    {
                        "accuracy": 0.803263,
                        "f1": 0.689341,
                        "f1_weighted": 0.831247,
                        "ap": 0.949357,
                        "ap_weighted": 0.949357
                    },
                    {
                        "accuracy": 0.804223,
                        "f1": 0.660478,
                        "f1_weighted": 0.82712,
                        "ap": 0.929645,
                        "ap_weighted": 0.929645
                    },
                    {
                        "accuracy": 0.573896,
                        "f1": 0.519007,
                        "f1_weighted": 0.641573,
                        "ap": 0.935585,
                        "ap_weighted": 0.935585
                    },
                    {
                        "accuracy": 0.75144,
                        "f1": 0.656886,
                        "f1_weighted": 0.792753,
                        "ap": 0.955756,
                        "ap_weighted": 0.955756
                    },
                    {
                        "accuracy": 0.704415,
                        "f1": 0.601254,
                        "f1_weighted": 0.754243,
                        "ap": 0.934777,
                        "ap_weighted": 0.934777
                    },
                    {
                        "accuracy": 0.84357,
                        "f1": 0.723285,
                        "f1_weighted": 0.860904,
                        "ap": 0.948757,
                        "ap_weighted": 0.948757
                    },
                    {
                        "accuracy": 0.643954,
                        "f1": 0.541266,
                        "f1_weighted": 0.704983,
                        "ap": 0.91539,
                        "ap_weighted": 0.91539
                    },
                    {
                        "accuracy": 0.795585,
                        "f1": 0.685216,
                        "f1_weighted": 0.825816,
                        "ap": 0.950971,
                        "ap_weighted": 0.950971
                    },
                    {
                        "accuracy": 0.825336,
                        "f1": 0.709491,
                        "f1_weighted": 0.847871,
                        "ap": 0.950642,
                        "ap_weighted": 0.950642
                    },
                    {
                        "accuracy": 0.747601,
                        "f1": 0.646627,
                        "f1_weighted": 0.789114,
                        "ap": 0.9488,
                        "ap_weighted": 0.9488
                    }
                ],
                "main_score": 0.749328,
                "hf_subset": "default",
                "languages": [
                    "slk-Latn"
                ]
            }
        ]
    },
    "evaluation_time": 19.393388509750366,
    "kg_co2_emissions": null
}
