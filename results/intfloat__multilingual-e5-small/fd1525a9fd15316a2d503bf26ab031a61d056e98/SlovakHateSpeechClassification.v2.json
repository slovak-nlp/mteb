{
    "dataset_revision": "691fe861df0ffa25066cbf6da8e64ebd296af6ab",
    "task_name": "SlovakHateSpeechClassification.v2",
    "mteb_version": "1.39.7",
    "scores": {
        "test": [
            {
                "accuracy": 0.546483,
                "f1": 0.518054,
                "f1_weighted": 0.568063,
                "ap": 0.302924,
                "ap_weighted": 0.302924,
                "scores_per_experiment": [
                    {
                        "accuracy": 0.510105,
                        "f1": 0.476135,
                        "f1_weighted": 0.535125,
                        "ap": 0.276578,
                        "ap_weighted": 0.276578
                    },
                    {
                        "accuracy": 0.549717,
                        "f1": 0.495355,
                        "f1_weighted": 0.568597,
                        "ap": 0.280089,
                        "ap_weighted": 0.280089
                    },
                    {
                        "accuracy": 0.56831,
                        "f1": 0.541142,
                        "f1_weighted": 0.590515,
                        "ap": 0.314557,
                        "ap_weighted": 0.314557
                    },
                    {
                        "accuracy": 0.594988,
                        "f1": 0.54278,
                        "f1_weighted": 0.6111,
                        "ap": 0.304959,
                        "ap_weighted": 0.304959
                    },
                    {
                        "accuracy": 0.516572,
                        "f1": 0.501223,
                        "f1_weighted": 0.539914,
                        "ap": 0.299506,
                        "ap_weighted": 0.299506
                    },
                    {
                        "accuracy": 0.514956,
                        "f1": 0.500702,
                        "f1_weighted": 0.538006,
                        "ap": 0.300253,
                        "ap_weighted": 0.300253
                    },
                    {
                        "accuracy": 0.58367,
                        "f1": 0.555771,
                        "f1_weighted": 0.605,
                        "ap": 0.323714,
                        "ap_weighted": 0.323714
                    },
                    {
                        "accuracy": 0.56346,
                        "f1": 0.530229,
                        "f1_weighted": 0.585479,
                        "ap": 0.304458,
                        "ap_weighted": 0.304458
                    },
                    {
                        "accuracy": 0.529507,
                        "f1": 0.517768,
                        "f1_weighted": 0.551039,
                        "ap": 0.313431,
                        "ap_weighted": 0.313431
                    },
                    {
                        "accuracy": 0.533549,
                        "f1": 0.519434,
                        "f1_weighted": 0.555854,
                        "ap": 0.311696,
                        "ap_weighted": 0.311696
                    }
                ],
                "main_score": 0.546483,
                "hf_subset": "default",
                "languages": [
                    "slk-Latn"
                ]
            }
        ]
    },
    "evaluation_time": 18.303631067276,
    "kg_co2_emissions": null
}
