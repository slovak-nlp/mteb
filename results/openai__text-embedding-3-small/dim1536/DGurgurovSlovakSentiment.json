{
  "dataset_revision": "250a73199a3013bf9bf6b73b3fbdf83279b40375",
  "task_name": "DGurgurovSlovakSentiment",
  "mteb_version": "1.39.7",
  "scores": {
    "test": [
      {
        "accuracy": 0.879079,
        "f1": 0.785419,
        "f1_weighted": 0.892209,
        "ap": 0.967637,
        "ap_weighted": 0.967637,
        "scores_per_experiment": [
          {
            "accuracy": 0.846449,
            "f1": 0.745632,
            "f1_weighted": 0.866428,
            "ap": 0.964415,
            "ap_weighted": 0.964415
          },
          {
            "accuracy": 0.921305,
            "f1": 0.841231,
            "f1_weighted": 0.926283,
            "ap": 0.972113,
            "ap_weighted": 0.972113
          },
          {
            "accuracy": 0.835893,
            "f1": 0.729763,
            "f1_weighted": 0.857508,
            "ap": 0.959289,
            "ap_weighted": 0.959289
          },
          {
            "accuracy": 0.922265,
            "f1": 0.828215,
            "f1_weighted": 0.924095,
            "ap": 0.958769,
            "ap_weighted": 0.958769
          },
          {
            "accuracy": 0.898273,
            "f1": 0.811032,
            "f1_weighted": 0.907884,
            "ap": 0.972575,
            "ap_weighted": 0.972575
          },
          {
            "accuracy": 0.872361,
            "f1": 0.780071,
            "f1_weighted": 0.887537,
            "ap": 0.971733,
            "ap_weighted": 0.971733
          },
          {
            "accuracy": 0.892514,
            "f1": 0.806822,
            "f1_weighted": 0.903874,
            "ap": 0.975483,
            "ap_weighted": 0.975483
          },
          {
            "accuracy": 0.882917,
            "f1": 0.78662,
            "f1_weighted": 0.894748,
            "ap": 0.966757,
            "ap_weighted": 0.966757
          },
          {
            "accuracy": 0.872361,
            "f1": 0.774215,
            "f1_weighted": 0.886504,
            "ap": 0.966198,
            "ap_weighted": 0.966198
          },
          {
            "accuracy": 0.846449,
            "f1": 0.750586,
            "f1_weighted": 0.867224,
            "ap": 0.969041,
            "ap_weighted": 0.969041
          }
        ],
        "main_score": 0.879079,
        "hf_subset": "default",
        "languages": [
          "slk-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 29.220978021621704,
  "kg_co2_emissions": null
}