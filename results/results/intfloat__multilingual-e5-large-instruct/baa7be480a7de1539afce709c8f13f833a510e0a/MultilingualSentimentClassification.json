{
    "dataset_revision": "2b9b4d10fc589af67794141fe8cbd3739de1eb33",
    "task_name": "MultilingualSentimentClassification",
    "mteb_version": "1.39.7",
    "scores": {
        "test": [
            {
                "accuracy": 0.943474,
                "f1": 0.888963,
                "f1_weighted": 0.94762,
                "ap": 0.988081,
                "ap_weighted": 0.988081,
                "scores_per_experiment": [
                    {
                        "accuracy": 0.961612,
                        "f1": 0.918946,
                        "f1_weighted": 0.963305,
                        "ap": 0.989857,
                        "ap_weighted": 0.989857
                    },
                    {
                        "accuracy": 0.96737,
                        "f1": 0.927665,
                        "f1_weighted": 0.96809,
                        "ap": 0.985955,
                        "ap_weighted": 0.985955
                    },
                    {
                        "accuracy": 0.952975,
                        "f1": 0.903798,
                        "f1_weighted": 0.955681,
                        "ap": 0.989596,
                        "ap_weighted": 0.989596
                    },
                    {
                        "accuracy": 0.90595,
                        "f1": 0.831742,
                        "f1_weighted": 0.91603,
                        "ap": 0.984915,
                        "ap_weighted": 0.984915
                    },
                    {
                        "accuracy": 0.949136,
                        "f1": 0.897098,
                        "f1_weighted": 0.952297,
                        "ap": 0.989058,
                        "ap_weighted": 0.989058
                    },
                    {
                        "accuracy": 0.949136,
                        "f1": 0.896525,
                        "f1_weighted": 0.952181,
                        "ap": 0.98811,
                        "ap_weighted": 0.98811
                    },
                    {
                        "accuracy": 0.928983,
                        "f1": 0.86478,
                        "f1_weighted": 0.935063,
                        "ap": 0.987187,
                        "ap_weighted": 0.987187
                    },
                    {
                        "accuracy": 0.958733,
                        "f1": 0.914126,
                        "f1_weighted": 0.960812,
                        "ap": 0.990402,
                        "ap_weighted": 0.990402
                    },
                    {
                        "accuracy": 0.935701,
                        "f1": 0.875363,
                        "f1_weighted": 0.940777,
                        "ap": 0.988128,
                        "ap_weighted": 0.988128
                    },
                    {
                        "accuracy": 0.925144,
                        "f1": 0.859583,
                        "f1_weighted": 0.931958,
                        "ap": 0.987603,
                        "ap_weighted": 0.987603
                    }
                ],
                "main_score": 0.943474,
                "hf_subset": "slk",
                "languages": [
                    "slk-Latn"
                ]
            }
        ]
    },
    "evaluation_time": 18.829415559768677,
    "kg_co2_emissions": null
}
