{
    "dataset_revision": "250a73199a3013bf9bf6b73b3fbdf83279b40375",
    "task_name": "DGurgurovSlovakSentiment",
    "mteb_version": "1.39.7",
    "scores": {
        "test": [
            {
                "accuracy": 0.568618,
                "f1": 0.513382,
                "f1_weighted": 0.633313,
                "ap": 0.933035,
                "ap_weighted": 0.933035,
                "scores_per_experiment": [
                    {
                        "accuracy": 0.552783,
                        "f1": 0.505568,
                        "f1_weighted": 0.62082,
                        "ap": 0.936413,
                        "ap_weighted": 0.936413
                    },
                    {
                        "accuracy": 0.6238,
                        "f1": 0.549991,
                        "f1_weighted": 0.687465,
                        "ap": 0.93427,
                        "ap_weighted": 0.93427
                    },
                    {
                        "accuracy": 0.612284,
                        "f1": 0.545275,
                        "f1_weighted": 0.676948,
                        "ap": 0.937233,
                        "ap_weighted": 0.937233
                    },
                    {
                        "accuracy": 0.658349,
                        "f1": 0.584211,
                        "f1_weighted": 0.716649,
                        "ap": 0.947404,
                        "ap_weighted": 0.947404
                    },
                    {
                        "accuracy": 0.455854,
                        "f1": 0.429242,
                        "f1_weighted": 0.522207,
                        "ap": 0.920945,
                        "ap_weighted": 0.920945
                    },
                    {
                        "accuracy": 0.449136,
                        "f1": 0.424878,
                        "f1_weighted": 0.513975,
                        "ap": 0.921898,
                        "ap_weighted": 0.921898
                    },
                    {
                        "accuracy": 0.481766,
                        "f1": 0.442051,
                        "f1_weighted": 0.554338,
                        "ap": 0.912759,
                        "ap_weighted": 0.912759
                    },
                    {
                        "accuracy": 0.556622,
                        "f1": 0.506526,
                        "f1_weighted": 0.625127,
                        "ap": 0.934107,
                        "ap_weighted": 0.934107
                    },
                    {
                        "accuracy": 0.650672,
                        "f1": 0.576531,
                        "f1_weighted": 0.710189,
                        "ap": 0.944456,
                        "ap_weighted": 0.944456
                    },
                    {
                        "accuracy": 0.644914,
                        "f1": 0.56955,
                        "f1_weighted": 0.705412,
                        "ap": 0.940869,
                        "ap_weighted": 0.940869
                    }
                ],
                "main_score": 0.568618,
                "hf_subset": "default",
                "languages": [
                    "slk-Latn"
                ]
            }
        ]
    },
    "evaluation_time": 17.413846731185913,
    "kg_co2_emissions": null
}
