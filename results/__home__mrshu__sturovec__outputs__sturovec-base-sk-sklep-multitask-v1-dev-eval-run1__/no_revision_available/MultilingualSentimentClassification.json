{
    "dataset_revision": "2b9b4d10fc589af67794141fe8cbd3739de1eb33",
    "task_name": "MultilingualSentimentClassification",
    "mteb_version": "1.39.7",
    "scores": {
        "test": [
            {
                "accuracy": 0.841651,
                "f1": 0.754142,
                "f1_weighted": 0.864283,
                "ap": 0.973018,
                "ap_weighted": 0.973018,
                "scores_per_experiment": [
                    {
                        "accuracy": 0.8119,
                        "f1": 0.72044,
                        "f1_weighted": 0.841057,
                        "ap": 0.970792,
                        "ap_weighted": 0.970792
                    },
                    {
                        "accuracy": 0.869482,
                        "f1": 0.766499,
                        "f1_weighted": 0.883471,
                        "ap": 0.962157,
                        "ap_weighted": 0.962157
                    },
                    {
                        "accuracy": 0.903071,
                        "f1": 0.826194,
                        "f1_weighted": 0.913388,
                        "ap": 0.982608,
                        "ap_weighted": 0.982608
                    },
                    {
                        "accuracy": 0.824376,
                        "f1": 0.735949,
                        "f1_weighted": 0.851212,
                        "ap": 0.975405,
                        "ap_weighted": 0.975405
                    },
                    {
                        "accuracy": 0.740883,
                        "f1": 0.655828,
                        "f1_weighted": 0.784888,
                        "ap": 0.962754,
                        "ap_weighted": 0.962754
                    },
                    {
                        "accuracy": 0.828215,
                        "f1": 0.739093,
                        "f1_weighted": 0.854117,
                        "ap": 0.974984,
                        "ap_weighted": 0.974984
                    },
                    {
                        "accuracy": 0.900192,
                        "f1": 0.81549,
                        "f1_weighted": 0.90979,
                        "ap": 0.974695,
                        "ap_weighted": 0.974695
                    },
                    {
                        "accuracy": 0.804223,
                        "f1": 0.709974,
                        "f1_weighted": 0.834687,
                        "ap": 0.966879,
                        "ap_weighted": 0.966879
                    },
                    {
                        "accuracy": 0.908829,
                        "f1": 0.835004,
                        "f1_weighted": 0.918256,
                        "ap": 0.984365,
                        "ap_weighted": 0.984365
                    },
                    {
                        "accuracy": 0.825336,
                        "f1": 0.736952,
                        "f1_weighted": 0.851968,
                        "ap": 0.975539,
                        "ap_weighted": 0.975539
                    }
                ],
                "main_score": 0.841651,
                "hf_subset": "slk",
                "languages": [
                    "slk-Latn"
                ]
            }
        ]
    },
    "evaluation_time": 19.51517653465271,
    "kg_co2_emissions": null
}
