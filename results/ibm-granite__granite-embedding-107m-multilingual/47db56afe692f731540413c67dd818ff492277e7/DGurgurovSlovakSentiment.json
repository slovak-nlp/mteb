{
    "dataset_revision": "250a73199a3013bf9bf6b73b3fbdf83279b40375",
    "task_name": "DGurgurovSlovakSentiment",
    "mteb_version": "1.39.7",
    "scores": {
        "test": [
            {
                "accuracy": 0.747313,
                "f1": 0.649508,
                "f1_weighted": 0.788646,
                "ap": 0.950717,
                "ap_weighted": 0.950717,
                "scores_per_experiment": [
                    {
                        "accuracy": 0.78119,
                        "f1": 0.682963,
                        "f1_weighted": 0.816077,
                        "ap": 0.958987,
                        "ap_weighted": 0.958987
                    },
                    {
                        "accuracy": 0.763916,
                        "f1": 0.652508,
                        "f1_weighted": 0.800925,
                        "ap": 0.943898,
                        "ap_weighted": 0.943898
                    },
                    {
                        "accuracy": 0.704415,
                        "f1": 0.610335,
                        "f1_weighted": 0.754762,
                        "ap": 0.942784,
                        "ap_weighted": 0.942784
                    },
                    {
                        "accuracy": 0.708253,
                        "f1": 0.620073,
                        "f1_weighted": 0.75814,
                        "ap": 0.949719,
                        "ap_weighted": 0.949719
                    },
                    {
                        "accuracy": 0.738004,
                        "f1": 0.639341,
                        "f1_weighted": 0.781633,
                        "ap": 0.94837,
                        "ap_weighted": 0.94837
                    },
                    {
                        "accuracy": 0.746641,
                        "f1": 0.654551,
                        "f1_weighted": 0.789092,
                        "ap": 0.956946,
                        "ap_weighted": 0.956946
                    },
                    {
                        "accuracy": 0.822457,
                        "f1": 0.706474,
                        "f1_weighted": 0.845653,
                        "ap": 0.950243,
                        "ap_weighted": 0.950243
                    },
                    {
                        "accuracy": 0.735125,
                        "f1": 0.638849,
                        "f1_weighted": 0.779505,
                        "ap": 0.949792,
                        "ap_weighted": 0.949792
                    },
                    {
                        "accuracy": 0.784069,
                        "f1": 0.684684,
                        "f1_weighted": 0.818217,
                        "ap": 0.958465,
                        "ap_weighted": 0.958465
                    },
                    {
                        "accuracy": 0.68906,
                        "f1": 0.605305,
                        "f1_weighted": 0.742453,
                        "ap": 0.947963,
                        "ap_weighted": 0.947963
                    }
                ],
                "main_score": 0.747313,
                "hf_subset": "default",
                "languages": [
                    "slk-Latn"
                ]
            }
        ]
    },
    "evaluation_time": 19.151143074035645,
    "kg_co2_emissions": null
}
