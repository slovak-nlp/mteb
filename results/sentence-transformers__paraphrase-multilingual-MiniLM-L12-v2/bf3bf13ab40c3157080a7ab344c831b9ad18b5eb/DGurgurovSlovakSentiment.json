{
    "dataset_revision": "250a73199a3013bf9bf6b73b3fbdf83279b40375",
    "task_name": "DGurgurovSlovakSentiment",
    "mteb_version": "1.39.7",
    "scores": {
        "test": [
            {
                "accuracy": 0.890115,
                "f1": 0.807782,
                "f1_weighted": 0.902377,
                "ap": 0.975725,
                "ap_weighted": 0.975725,
                "scores_per_experiment": [
                    {
                        "accuracy": 0.887716,
                        "f1": 0.803134,
                        "f1_weighted": 0.900471,
                        "ap": 0.977624,
                        "ap_weighted": 0.977624
                    },
                    {
                        "accuracy": 0.90595,
                        "f1": 0.818166,
                        "f1_weighted": 0.913468,
                        "ap": 0.96997,
                        "ap_weighted": 0.96997
                    },
                    {
                        "accuracy": 0.913628,
                        "f1": 0.835543,
                        "f1_weighted": 0.921023,
                        "ap": 0.977504,
                        "ap_weighted": 0.977504
                    },
                    {
                        "accuracy": 0.908829,
                        "f1": 0.83023,
                        "f1_weighted": 0.917365,
                        "ap": 0.978701,
                        "ap_weighted": 0.978701
                    },
                    {
                        "accuracy": 0.890595,
                        "f1": 0.806035,
                        "f1_weighted": 0.90264,
                        "ap": 0.977087,
                        "ap_weighted": 0.977087
                    },
                    {
                        "accuracy": 0.926104,
                        "f1": 0.853714,
                        "f1_weighted": 0.931338,
                        "ap": 0.978318,
                        "ap_weighted": 0.978318
                    },
                    {
                        "accuracy": 0.859885,
                        "f1": 0.767889,
                        "f1_weighted": 0.878116,
                        "ap": 0.97279,
                        "ap_weighted": 0.97279
                    },
                    {
                        "accuracy": 0.907869,
                        "f1": 0.828859,
                        "f1_weighted": 0.916574,
                        "ap": 0.978566,
                        "ap_weighted": 0.978566
                    },
                    {
                        "accuracy": 0.915547,
                        "f1": 0.839198,
                        "f1_weighted": 0.922778,
                        "ap": 0.978705,
                        "ap_weighted": 0.978705
                    },
                    {
                        "accuracy": 0.785029,
                        "f1": 0.695054,
                        "f1_weighted": 0.820001,
                        "ap": 0.967982,
                        "ap_weighted": 0.967982
                    }
                ],
                "main_score": 0.890115,
                "hf_subset": "default",
                "languages": [
                    "slk-Latn"
                ]
            }
        ]
    },
    "evaluation_time": 17.428963661193848,
    "kg_co2_emissions": null
}
