{
    "dataset_revision": "691fe861df0ffa25066cbf6da8e64ebd296af6ab",
    "task_name": "SlovakHateSpeechClassification.v2",
    "mteb_version": "1.39.7",
    "scores": {
        "test": [
            {
                "accuracy": 0.539854,
                "f1": 0.516378,
                "f1_weighted": 0.555264,
                "ap": 0.311814,
                "ap_weighted": 0.311814,
                "scores_per_experiment": [
                    {
                        "accuracy": 0.452708,
                        "f1": 0.449796,
                        "f1_weighted": 0.467497,
                        "ap": 0.288516,
                        "ap_weighted": 0.288516
                    },
                    {
                        "accuracy": 0.576395,
                        "f1": 0.557901,
                        "f1_weighted": 0.597885,
                        "ap": 0.332925,
                        "ap_weighted": 0.332925
                    },
                    {
                        "accuracy": 0.435732,
                        "f1": 0.43365,
                        "f1_weighted": 0.448834,
                        "ap": 0.282307,
                        "ap_weighted": 0.282307
                    },
                    {
                        "accuracy": 0.529507,
                        "f1": 0.519898,
                        "f1_weighted": 0.549932,
                        "ap": 0.317737,
                        "ap_weighted": 0.317737
                    },
                    {
                        "accuracy": 0.547292,
                        "f1": 0.530341,
                        "f1_weighted": 0.569796,
                        "ap": 0.315719,
                        "ap_weighted": 0.315719
                    },
                    {
                        "accuracy": 0.506063,
                        "f1": 0.497871,
                        "f1_weighted": 0.526232,
                        "ap": 0.305964,
                        "ap_weighted": 0.305964
                    },
                    {
                        "accuracy": 0.545675,
                        "f1": 0.528664,
                        "f1_weighted": 0.56826,
                        "ap": 0.314582,
                        "ap_weighted": 0.314582
                    },
                    {
                        "accuracy": 0.669361,
                        "f1": 0.565854,
                        "f1_weighted": 0.659593,
                        "ap": 0.314607,
                        "ap_weighted": 0.314607
                    },
                    {
                        "accuracy": 0.646726,
                        "f1": 0.59502,
                        "f1_weighted": 0.659009,
                        "ap": 0.340579,
                        "ap_weighted": 0.340579
                    },
                    {
                        "accuracy": 0.489086,
                        "f1": 0.484787,
                        "f1_weighted": 0.505599,
                        "ap": 0.305204,
                        "ap_weighted": 0.305204
                    }
                ],
                "main_score": 0.539854,
                "hf_subset": "default",
                "languages": [
                    "slk-Latn"
                ]
            }
        ]
    },
    "evaluation_time": 18.091084957122803,
    "kg_co2_emissions": null
}
