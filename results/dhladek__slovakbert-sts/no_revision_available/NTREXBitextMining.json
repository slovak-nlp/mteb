{
    "dataset_revision": "ed9a4403ed4adbfaf4aab56d5b2709e9f6c3ba33",
    "task_name": "NTREXBitextMining",
    "mteb_version": "1.39.7",
    "scores": {
        "test": [
            {
                "precision": 0.000221,
                "recall": 0.001502,
                "f1": 0.000353,
                "accuracy": 0.001502,
                "main_score": 0.000353,
                "hf_subset": "bel_Cyrl-slk_Latn",
                "languages": [
                    "bel-Cyrl",
                    "slk-Latn"
                ]
            },
            {
                "precision": 0.013414,
                "recall": 0.022033,
                "f1": 0.014974,
                "accuracy": 0.022033,
                "main_score": 0.014974,
                "hf_subset": "bos_Latn-slk_Latn",
                "languages": [
                    "bos-Latn",
                    "slk-Latn"
                ]
            },
            {
                "precision": 0.001298,
                "recall": 0.003005,
                "f1": 0.001486,
                "accuracy": 0.003005,
                "main_score": 0.001486,
                "hf_subset": "bul_Cyrl-slk_Latn",
                "languages": [
                    "bul-Cyrl",
                    "slk-Latn"
                ]
            },
            {
                "precision": 0.125003,
                "recall": 0.166249,
                "f1": 0.135549,
                "accuracy": 0.166249,
                "main_score": 0.135549,
                "hf_subset": "ces_Latn-slk_Latn",
                "languages": [
                    "ces-Latn",
                    "slk-Latn"
                ]
            },
            {
                "precision": 0.021232,
                "recall": 0.037056,
                "f1": 0.024055,
                "accuracy": 0.037056,
                "main_score": 0.024055,
                "hf_subset": "eng_Latn-slk_Latn",
                "languages": [
                    "eng-Latn",
                    "slk-Latn"
                ]
            },
            {
                "precision": 0.010745,
                "recall": 0.017526,
                "f1": 0.012113,
                "accuracy": 0.017526,
                "main_score": 0.012113,
                "hf_subset": "hrv_Latn-slk_Latn",
                "languages": [
                    "hrv-Latn",
                    "slk-Latn"
                ]
            },
            {
                "precision": 0.000286,
                "recall": 0.002003,
                "f1": 0.000455,
                "accuracy": 0.002003,
                "main_score": 0.000455,
                "hf_subset": "mkd_Cyrl-slk_Latn",
                "languages": [
                    "mkd-Cyrl",
                    "slk-Latn"
                ]
            },
            {
                "precision": 0.006981,
                "recall": 0.014522,
                "f1": 0.008354,
                "accuracy": 0.014522,
                "main_score": 0.008354,
                "hf_subset": "pol_Latn-slk_Latn",
                "languages": [
                    "pol-Latn",
                    "slk-Latn"
                ]
            },
            {
                "precision": 0.001115,
                "recall": 0.003005,
                "f1": 0.001419,
                "accuracy": 0.003005,
                "main_score": 0.001419,
                "hf_subset": "rus_Cyrl-slk_Latn",
                "languages": [
                    "rus-Cyrl",
                    "slk-Latn"
                ]
            },
            {
                "precision": 0.000333,
                "recall": 0.002003,
                "f1": 0.000489,
                "accuracy": 0.002003,
                "main_score": 0.000489,
                "hf_subset": "slk_Latn-bel_Cyrl",
                "languages": [
                    "slk-Latn",
                    "bel-Cyrl"
                ]
            },
            {
                "precision": 0.016624,
                "recall": 0.026039,
                "f1": 0.018371,
                "accuracy": 0.026039,
                "main_score": 0.018371,
                "hf_subset": "slk_Latn-bos_Latn",
                "languages": [
                    "slk-Latn",
                    "bos-Latn"
                ]
            },
            {
                "precision": 0.001391,
                "recall": 0.003505,
                "f1": 0.001591,
                "accuracy": 0.003505,
                "main_score": 0.001591,
                "hf_subset": "slk_Latn-bul_Cyrl",
                "languages": [
                    "slk-Latn",
                    "bul-Cyrl"
                ]
            },
            {
                "precision": 0.125559,
                "recall": 0.169755,
                "f1": 0.136947,
                "accuracy": 0.169755,
                "main_score": 0.136947,
                "hf_subset": "slk_Latn-ces_Latn",
                "languages": [
                    "slk-Latn",
                    "ces-Latn"
                ]
            },
            {
                "precision": 0.030159,
                "recall": 0.040561,
                "f1": 0.032107,
                "accuracy": 0.040561,
                "main_score": 0.032107,
                "hf_subset": "slk_Latn-eng_Latn",
                "languages": [
                    "slk-Latn",
                    "eng-Latn"
                ]
            },
            {
                "precision": 0.012629,
                "recall": 0.024036,
                "f1": 0.014805,
                "accuracy": 0.024036,
                "main_score": 0.014805,
                "hf_subset": "slk_Latn-hrv_Latn",
                "languages": [
                    "slk-Latn",
                    "hrv-Latn"
                ]
            },
            {
                "precision": 0.00074,
                "recall": 0.003005,
                "f1": 0.001129,
                "accuracy": 0.003005,
                "main_score": 0.001129,
                "hf_subset": "slk_Latn-mkd_Cyrl",
                "languages": [
                    "slk-Latn",
                    "mkd-Cyrl"
                ]
            },
            {
                "precision": 0.008271,
                "recall": 0.015023,
                "f1": 0.009662,
                "accuracy": 0.015023,
                "main_score": 0.009662,
                "hf_subset": "slk_Latn-pol_Latn",
                "languages": [
                    "slk-Latn",
                    "pol-Latn"
                ]
            },
            {
                "precision": 0.000835,
                "recall": 0.004006,
                "f1": 0.00105,
                "accuracy": 0.004006,
                "main_score": 0.00105,
                "hf_subset": "slk_Latn-rus_Cyrl",
                "languages": [
                    "slk-Latn",
                    "rus-Cyrl"
                ]
            },
            {
                "precision": 0.015829,
                "recall": 0.023535,
                "f1": 0.017709,
                "accuracy": 0.023535,
                "main_score": 0.017709,
                "hf_subset": "slk_Latn-slv_Latn",
                "languages": [
                    "slk-Latn",
                    "slv-Latn"
                ]
            },
            {
                "precision": 0.000579,
                "recall": 0.001502,
                "f1": 0.000645,
                "accuracy": 0.001502,
                "main_score": 0.000645,
                "hf_subset": "slk_Latn-srp_Cyrl",
                "languages": [
                    "slk-Latn",
                    "srp-Cyrl"
                ]
            },
            {
                "precision": 0.013699,
                "recall": 0.025538,
                "f1": 0.015775,
                "accuracy": 0.025538,
                "main_score": 0.015775,
                "hf_subset": "slk_Latn-srp_Latn",
                "languages": [
                    "slk-Latn",
                    "srp-Latn"
                ]
            },
            {
                "precision": 0.00057,
                "recall": 0.002003,
                "f1": 0.000628,
                "accuracy": 0.002003,
                "main_score": 0.000628,
                "hf_subset": "slk_Latn-ukr_Cyrl",
                "languages": [
                    "slk-Latn",
                    "ukr-Cyrl"
                ]
            },
            {
                "precision": 0.0114,
                "recall": 0.021032,
                "f1": 0.013222,
                "accuracy": 0.021032,
                "main_score": 0.013222,
                "hf_subset": "slv_Latn-slk_Latn",
                "languages": [
                    "slv-Latn",
                    "slk-Latn"
                ]
            },
            {
                "precision": 0.000635,
                "recall": 0.002003,
                "f1": 0.00074,
                "accuracy": 0.002003,
                "main_score": 0.00074,
                "hf_subset": "srp_Cyrl-slk_Latn",
                "languages": [
                    "srp-Cyrl",
                    "slk-Latn"
                ]
            },
            {
                "precision": 0.009587,
                "recall": 0.019029,
                "f1": 0.01124,
                "accuracy": 0.019029,
                "main_score": 0.01124,
                "hf_subset": "srp_Latn-slk_Latn",
                "languages": [
                    "srp-Latn",
                    "slk-Latn"
                ]
            },
            {
                "precision": 0.000848,
                "recall": 0.002504,
                "f1": 0.001013,
                "accuracy": 0.002504,
                "main_score": 0.001013,
                "hf_subset": "ukr_Cyrl-slk_Latn",
                "languages": [
                    "ukr-Cyrl",
                    "slk-Latn"
                ]
            }
        ]
    },
    "evaluation_time": 105.49054026603699,
    "kg_co2_emissions": null
}
