{
    "dataset_revision": "2b9b4d10fc589af67794141fe8cbd3739de1eb33",
    "task_name": "MultilingualSentimentClassification",
    "mteb_version": "1.39.7",
    "scores": {
        "test": [
            {
                "accuracy": 0.858829,
                "f1": 0.767596,
                "f1_weighted": 0.877317,
                "ap": 0.97229,
                "ap_weighted": 0.97229,
                "scores_per_experiment": [
                    {
                        "accuracy": 0.81286,
                        "f1": 0.711818,
                        "f1_weighted": 0.840536,
                        "ap": 0.961564,
                        "ap_weighted": 0.961564
                    },
                    {
                        "accuracy": 0.882917,
                        "f1": 0.789574,
                        "f1_weighted": 0.895291,
                        "ap": 0.969507,
                        "ap_weighted": 0.969507
                    },
                    {
                        "accuracy": 0.845489,
                        "f1": 0.754209,
                        "f1_weighted": 0.867196,
                        "ap": 0.973599,
                        "ap_weighted": 0.973599
                    },
                    {
                        "accuracy": 0.859885,
                        "f1": 0.767889,
                        "f1_weighted": 0.878116,
                        "ap": 0.97279,
                        "ap_weighted": 0.97279
                    },
                    {
                        "accuracy": 0.850288,
                        "f1": 0.754921,
                        "f1_weighted": 0.870242,
                        "ap": 0.969577,
                        "ap_weighted": 0.969577
                    },
                    {
                        "accuracy": 0.886756,
                        "f1": 0.802754,
                        "f1_weighted": 0.899851,
                        "ap": 0.978432,
                        "ap_weighted": 0.978432
                    },
                    {
                        "accuracy": 0.887716,
                        "f1": 0.796795,
                        "f1_weighted": 0.899326,
                        "ap": 0.9711,
                        "ap_weighted": 0.9711
                    },
                    {
                        "accuracy": 0.889635,
                        "f1": 0.805641,
                        "f1_weighted": 0.90202,
                        "ap": 0.977892,
                        "ap_weighted": 0.977892
                    },
                    {
                        "accuracy": 0.826296,
                        "f1": 0.735274,
                        "f1_weighted": 0.852366,
                        "ap": 0.972808,
                        "ap_weighted": 0.972808
                    },
                    {
                        "accuracy": 0.846449,
                        "f1": 0.757088,
                        "f1_weighted": 0.868224,
                        "ap": 0.97563,
                        "ap_weighted": 0.97563
                    }
                ],
                "main_score": 0.858829,
                "hf_subset": "slk",
                "languages": [
                    "slk-Latn"
                ]
            }
        ]
    },
    "evaluation_time": 18.83206343650818,
    "kg_co2_emissions": null
}
