{
    "dataset_revision": "250a73199a3013bf9bf6b73b3fbdf83279b40375",
    "task_name": "DGurgurovSlovakSentiment",
    "mteb_version": "1.39.7",
    "scores": {
        "test": [
            {
                "accuracy": 0.888292,
                "f1": 0.798439,
                "f1_weighted": 0.899743,
                "ap": 0.969002,
                "ap_weighted": 0.969002,
                "scores_per_experiment": [
                    {
                        "accuracy": 0.87524,
                        "f1": 0.780776,
                        "f1_weighted": 0.889327,
                        "ap": 0.969357,
                        "ap_weighted": 0.969357
                    },
                    {
                        "accuracy": 0.901152,
                        "f1": 0.805358,
                        "f1_weighted": 0.908359,
                        "ap": 0.963858,
                        "ap_weighted": 0.963858
                    },
                    {
                        "accuracy": 0.923225,
                        "f1": 0.839772,
                        "f1_weighted": 0.926998,
                        "ap": 0.967833,
                        "ap_weighted": 0.967833
                    },
                    {
                        "accuracy": 0.849328,
                        "f1": 0.757597,
                        "f1_weighted": 0.870079,
                        "ap": 0.973192,
                        "ap_weighted": 0.973192
                    },
                    {
                        "accuracy": 0.81094,
                        "f1": 0.706803,
                        "f1_weighted": 0.83861,
                        "ap": 0.958542,
                        "ap_weighted": 0.958542
                    },
                    {
                        "accuracy": 0.917466,
                        "f1": 0.831629,
                        "f1_weighted": 0.922312,
                        "ap": 0.967936,
                        "ap_weighted": 0.967936
                    },
                    {
                        "accuracy": 0.884837,
                        "f1": 0.793024,
                        "f1_weighted": 0.897008,
                        "ap": 0.970697,
                        "ap_weighted": 0.970697
                    },
                    {
                        "accuracy": 0.885797,
                        "f1": 0.797072,
                        "f1_weighted": 0.898288,
                        "ap": 0.973612,
                        "ap_weighted": 0.973612
                    },
                    {
                        "accuracy": 0.916507,
                        "f1": 0.835594,
                        "f1_weighted": 0.922595,
                        "ap": 0.973278,
                        "ap_weighted": 0.973278
                    },
                    {
                        "accuracy": 0.918426,
                        "f1": 0.836766,
                        "f1_weighted": 0.923855,
                        "ap": 0.971711,
                        "ap_weighted": 0.971711
                    }
                ],
                "main_score": 0.888292,
                "hf_subset": "default",
                "languages": [
                    "slk-Latn"
                ]
            }
        ]
    },
    "evaluation_time": 23.437462091445923,
    "kg_co2_emissions": null
}
